{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import torch, os, monai\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import SamProcessor, SamModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1765211235261,
     "user": {
      "displayName": "Shanna Fernlie",
      "userId": "14829187662547582475"
     },
     "user_tz": -420
    },
    "id": "LfXGdV7xuBfV",
    "outputId": "fb676949-5f19-4378-ca6e-0d60f3be8abd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test images: 1867\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "TEST_IMAGES_DIR = \"/content/drive/MyDrive/Kuliah/Skripsi S1/test/images\"\n",
    "TEST_MASKS_DIR  = \"/content/drive/MyDrive/Kuliah/Skripsi S1/test/targets\"\n",
    "\n",
    "all_test_imgs = sorted(\n",
    "    f for f in os.listdir(TEST_IMAGES_DIR)\n",
    "    if os.path.isfile(os.path.join(TEST_IMAGES_DIR, f)) and f.endswith(\".png\")\n",
    ")\n",
    "\n",
    "print(\"Total test images:\", len(all_test_imgs))\n",
    "\n",
    "sam_iou  = 0.0\n",
    "sam_dice = 0.0\n",
    "sam_bf   = 0.0\n",
    "n_used   = 0\n",
    "\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWmlnw1zJCUK"
   },
   "source": [
    "## Zero-shot SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the baseline VIT-B SAM model being evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14050,
     "status": "ok",
     "timestamp": 1765268364792,
     "user": {
      "displayName": "Shanna Fernlie",
      "userId": "14829187662547582475"
     },
     "user_tz": -420
    },
    "id": "Ve9ZNnFlJFz-",
    "outputId": "ccae332f-d1c0-4205-a641-3c9daf967ecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test images found: 1867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sam_checkpoint = \"/content/sam_vit_b_01ec64.pth\"\n",
    "model_type = \"vit_b\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint).to(DEVICE)\n",
    "sam.eval()\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "TEST_IMAGES_DIR = \"/content/drive/MyDrive/Kuliah/Skripsi S1/test/images\"\n",
    "TEST_MASKS_DIR  = \"/content/drive/MyDrive/Kuliah/Skripsi S1/test/targets\"\n",
    "\n",
    "all_test_imgs = sorted(\n",
    "    f for f in os.listdir(TEST_IMAGES_DIR)\n",
    "    if os.path.isfile(os.path.join(TEST_IMAGES_DIR, f)) and f.endswith(\".png\")\n",
    ")\n",
    "\n",
    "print(\"Total test images found:\", len(all_test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_np(pred, gt, eps=1e-7):\n",
    "    pred = pred.astype(bool)\n",
    "    gt   = gt.astype(bool)\n",
    "    inter = np.logical_and(pred, gt).sum()\n",
    "    union = np.logical_or(pred, gt).sum()\n",
    "    return (inter + eps) / (union + eps)\n",
    "\n",
    "def dice_np(pred, gt, eps=1e-7):\n",
    "    pred = pred.astype(bool)\n",
    "    gt   = gt.astype(bool)\n",
    "    inter = np.logical_and(pred, gt).sum()\n",
    "    return (2 * inter + eps) / (pred.sum() + gt.sum() + eps)\n",
    "\n",
    "def boundary_f_score_np(pred, gt, dilation_ratio=0.02, eps=1e-7):\n",
    "    pred = pred.astype(np.uint8)\n",
    "    gt   = gt.astype(np.uint8)\n",
    "\n",
    "    h, w = pred.shape\n",
    "    if pred.max() == 0 and gt.max() == 0:\n",
    "        return 1.0\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    pred_erode = cv2.erode(pred, kernel, iterations=1)\n",
    "    gt_erode   = cv2.erode(gt,   kernel, iterations=1)\n",
    "    pred_b = pred - pred_erode\n",
    "    gt_b   = gt   - gt_erode\n",
    "\n",
    "    tol = max(1, int(round(dilation_ratio * max(h, w))))\n",
    "    dil_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*tol+1, 2*tol+1))\n",
    "    pred_dil = cv2.dilate(pred_b, dil_kernel)\n",
    "    gt_dil   = cv2.dilate(gt_b,   dil_kernel)\n",
    "\n",
    "    pred_match = np.logical_and(pred_b > 0, gt_dil > 0)\n",
    "    gt_match   = np.logical_and(gt_b   > 0, pred_dil > 0)\n",
    "\n",
    "    pred_b_sum = (pred_b > 0).sum()\n",
    "    gt_b_sum   = (gt_b   > 0).sum()\n",
    "    pred_match_sum = pred_match.sum()\n",
    "    gt_match_sum   = gt_match.sum()\n",
    "\n",
    "    if pred_b_sum == 0 and gt_b_sum == 0:\n",
    "        return 1.0\n",
    "    if pred_b_sum == 0 or gt_b_sum == 0:\n",
    "        return 0.0\n",
    "\n",
    "    precision = (pred_match_sum + eps) / (pred_b_sum + eps)\n",
    "    recall    = (gt_match_sum   + eps) / (gt_b_sum   + eps)\n",
    "    return (2 * precision * recall + eps) / (precision + recall + eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 769928,
     "status": "ok",
     "timestamp": 1765269262172,
     "user": {
      "displayName": "Shanna Fernlie",
      "userId": "14829187662547582475"
     },
     "user_tz": -420
    },
    "id": "ZzamiMvdMW8s",
    "outputId": "75f78b45-669d-4eef-c92c-159d473989f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SAM bbox test:  11%|█         | 200/1867 [12:49<1:46:57,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAM (pretrained) + 1 bbox per image (subset) ===\n",
      "Tiles used: 190\n",
      "IoU:  0.1693\n",
      "Dice: 0.2241\n",
      "BF:   0.4582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_TILES = 200\n",
    "\n",
    "sam_iou  = 0.0\n",
    "sam_dice = 0.0\n",
    "sam_bf   = 0.0\n",
    "n_used   = 0\n",
    "\n",
    "for i, fname in enumerate(tqdm(all_test_imgs, desc=\"SAM bbox test\")):\n",
    "    if i >= MAX_TILES:\n",
    "        break\n",
    "\n",
    "    img_path  = os.path.join(TEST_IMAGES_DIR, fname)\n",
    "\n",
    "    # handling weird duplicate files\n",
    "    base = fname[:-4]\n",
    "    base_clean = base.replace(\" (1)\", \"\")\n",
    "    mask_name = base_clean + \"_target.png\"\n",
    "    mask_path = os.path.join(TEST_MASKS_DIR, mask_name)\n",
    "\n",
    "    if not os.path.exists(mask_path):\n",
    "        print(\"Missing mask for:\", fname)\n",
    "        continue\n",
    "\n",
    "    image_bgr = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    if image_bgr is None:\n",
    "        continue\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    gt_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if gt_mask is None:\n",
    "        continue\n",
    "\n",
    "    gt_bin = (gt_mask > 0).astype(np.uint8)\n",
    "    if gt_bin.sum() == 0:\n",
    "        continue\n",
    "\n",
    "    H, W = gt_bin.shape\n",
    "    max_side = max(H, W)\n",
    "    if max_side > 512:\n",
    "        scale = 512.0 / max_side\n",
    "        new_w = int(round(W * scale))\n",
    "        new_h = int(round(H * scale))\n",
    "\n",
    "        image_rgb = cv2.resize(image_rgb, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "        gt_bin    = cv2.resize(gt_bin,    (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n",
    "        H, W = new_h, new_w\n",
    "\n",
    "    ys, xs = np.where(gt_bin > 0)\n",
    "    x_min, x_max = xs.min(), xs.max()\n",
    "    y_min, y_max = ys.min(), ys.max()\n",
    "    box = np.array([x_min, y_min, x_max, y_max])\n",
    "\n",
    "    predictor.set_image(image_rgb)\n",
    "    masks, scores, logits = predictor.predict(\n",
    "        box=box[None, :],\n",
    "        point_coords=None,\n",
    "        point_labels=None,\n",
    "        multimask_output=False\n",
    "    )\n",
    "\n",
    "    pred_mask = masks[0].astype(np.uint8)\n",
    "    # ensure same shape\n",
    "    if pred_mask.shape != gt_bin.shape:\n",
    "        pred_mask = cv2.resize(\n",
    "            pred_mask,\n",
    "            (gt_bin.shape[1], gt_bin.shape[0]),\n",
    "            interpolation=cv2.INTER_NEAREST\n",
    "        )\n",
    "\n",
    "    iou  = iou_np(pred_mask, gt_bin)\n",
    "    dice = dice_np(pred_mask, gt_bin)\n",
    "    bf   = boundary_f_score_np(pred_mask, gt_bin)\n",
    "\n",
    "    sam_iou  += iou\n",
    "    sam_dice += dice\n",
    "    sam_bf   += bf\n",
    "    n_used   += 1\n",
    "\n",
    "sam_iou  /= max(n_used, 1)\n",
    "sam_dice /= max(n_used, 1)\n",
    "sam_bf   /= max(n_used, 1)\n",
    "\n",
    "print(\"SAM (pretrained) + 1 bbox per image\")\n",
    "print(\"Tiles used:\", n_used)\n",
    "print(f\"IoU:  {sam_iou:.4f}\")\n",
    "print(f\"Dice: {sam_dice:.4f}\")\n",
    "print(f\"BF:   {sam_bf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuned SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this SAM is fine-tuned using 1 bbox per-image supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ROOT = \"/content/drive/MyDrive/Kuliah/Skripsi S1\"\n",
    "IMAGES_DIR = os.path.join(ROOT, \"train/images\")\n",
    "MASKS_DIR  = os.path.join(ROOT, \"train/targets\")\n",
    "SAVE_DIR = os.path.join(ROOT, \"checkpoints\")\n",
    "CACHE = os.path.join(ROOT, \"cache\")\n",
    "os.makedirs(CACHE, exist_ok=True)\n",
    "print('Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random\n",
    "\n",
    "pre_imgs = sorted(glob.glob(os.path.join(IMAGES_DIR, \"*_pre_disaster.png\")))\n",
    "print(\"Found PRE images:\", len(pre_imgs))\n",
    "\n",
    "pairs = []\n",
    "for ip in pre_imgs:\n",
    "    base = os.path.basename(ip)\n",
    "    mask_name = base.replace(\"_pre_disaster.png\", \"_pre_disaster_target.png\")\n",
    "    mp = os.path.join(MASKS_DIR, mask_name)\n",
    "    if os.path.exists(mp):\n",
    "        pairs.append((ip, mp))\n",
    "\n",
    "print(\"Paired (img,mask):\", len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_image_box(gt):\n",
    "    gt = (gt > 0).astype(np.uint8)\n",
    "    if gt.sum() == 0:\n",
    "        return None\n",
    "\n",
    "    ys, xs = np.where(gt > 0)\n",
    "    x0, x1 = xs.min(), xs.max()\n",
    "    y0, y1 = ys.min(), ys.max()\n",
    "    return [int(x0), int(y0), int(x1), int(y1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XBDForSAM(Dataset):\n",
    "    def __init__(self, pairs, processor, skip_empty=True):\n",
    "        self.samples = pairs\n",
    "        self.processor = processor\n",
    "        self.skip_empty = skip_empty\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ip, mp = self.samples[idx]\n",
    "        image = Image.open(ip).convert(\"RGB\")\n",
    "        mask  = Image.open(mp).convert(\"L\")\n",
    "        gt    = (np.array(mask) > 0).astype(np.uint8)\n",
    "\n",
    "        bbox = one_image_box(gt, mode=self.box_mode)\n",
    "\n",
    "        if bbox is None:\n",
    "            if self.skip_empty:\n",
    "                new_idx = np.random.randint(len(self.samples))\n",
    "                return self.__getitem__(new_idx)\n",
    "            bbox = [0, 0, 1, 1]\n",
    "\n",
    "        x0, y0, x1, y1 = map(float, bbox)\n",
    "        input_boxes = [[[x0, y0, x1, y1]]]\n",
    "\n",
    "        inputs = self.processor(image, input_boxes=input_boxes, return_tensors=\"pt\")\n",
    "        inputs = {k: v.squeeze(0) for k,v in inputs.items()}\n",
    "        inputs[\"ground_truth_mask\"] = gt.astype(np.uint8)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
    "# ds = XBDForSAM(pairs, processor)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    out = {}\n",
    "    for k in batch[0].keys():\n",
    "        if k == \"ground_truth_mask\":\n",
    "            ms = [torch.from_numpy(b[k]).to(torch.uint8) for b in batch]\n",
    "            out[k] = torch.stack(ms, dim=0).float()\n",
    "        else:\n",
    "            out[k] = torch.stack([b[k] for b in batch], dim=0)\n",
    "    return out\n",
    "\n",
    "train_pairs, val_pairs = train_test_split(pairs, test_size=0.1, random_state=42)\n",
    "\n",
    "train_ds = XBDForSAM(train_pairs, processor)\n",
    "val_ds   = XBDForSAM(val_pairs, processor)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# sanity check\n",
    "b = next(iter(train_dataloader))\n",
    "print(b[\"input_boxes\"].shape, b[\"ground_truth_mask\"].shape)\n",
    "for k,v in b.items():\n",
    "    print(k, tuple(v.shape))\n",
    "b = next(iter(val_dataloader))\n",
    "for k,v in b.items():\n",
    "    print(k, tuple(v.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sam = sam_model_registry[\"vit_b\"](\n",
    "    checkpoint=os.path.join(SAVE_DIR, \"sam_vit_b_01ec64.pth\")\n",
    ")\n",
    "sam.to(device)\n",
    "\n",
    "for p in sam.image_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in sam.prompt_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    sam.mask_decoder.parameters(), lr=1e-5\n",
    ")\n",
    "\n",
    "seg_loss = monai.losses.DiceCELoss(\n",
    "    sigmoid=True, squared_pred=True, reduction=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "model = SamModel.from_pretrained(\"./sam-vit-base\").to(device)\n",
    "\n",
    "ckpt = torch.load(f\"{SAVE_DIR}/best.pt\", map_location=device)\n",
    "model.load_state_dict(ckpt[\"model\"], strict=False)\n",
    "print(f\"Loaded fine-tuned weights from epoch {ckpt.get('epoch', '?')} (Dice={ckpt.get('best_dice', '?'):.3f})\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _norm_logits_shape(pred_masks):\n",
    "    logits = pred_masks\n",
    "    while logits.dim() > 4:\n",
    "        logits = logits.squeeze(1)\n",
    "    # Ensure channel = 1\n",
    "    if logits.dim() == 3:\n",
    "        logits = logits.unsqueeze(1)\n",
    "    if logits.shape[1] != 1:\n",
    "        logits = logits[:, :1, ...]\n",
    "    return logits\n",
    "\n",
    "def compute_dice_iou(pred, gt, eps=1e-6):\n",
    "    pred_bin = (pred > 0.5).float()\n",
    "    inter = (pred_bin * gt).sum(dim=(1,2,3))\n",
    "    union = (pred_bin + gt - pred_bin*gt).sum(dim=(1,2,3))\n",
    "    dice = (2*inter + eps) / (pred_bin.sum(dim=(1,2,3)) + gt.sum(dim=(1,2,3)) + eps)\n",
    "    iou  = (inter + eps) / (union + eps)\n",
    "    return dice.mean().item(), iou.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_iou(pred, gt, eps=1e-6):\n",
    "    pred_bin = (pred > 0.5).float()\n",
    "    inter = (pred_bin * gt).sum(dim=(1,2,3))\n",
    "    union = (pred_bin + gt - pred_bin*gt).sum(dim=(1,2,3))\n",
    "    dice = (2*inter + eps) / (pred_bin.sum(dim=(1,2,3)) + gt.sum(dim=(1,2,3)) + eps)\n",
    "    iou  = (inter + eps) / (union + eps)\n",
    "    return dice.mean().item(), iou.mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, dataloader, loss_fn=None):\n",
    "    model.eval()\n",
    "    dices, ious, losses = [], [], []\n",
    "    pbar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n",
    "\n",
    "    for batch in pbar:\n",
    "        pv = batch[\"pixel_values\"].to(device)\n",
    "        ib = batch[\"input_boxes\"].to(device)\n",
    "        gt = batch[\"ground_truth_mask\"].to(device).float().unsqueeze(1)\n",
    "\n",
    "        out = model(pixel_values=pv, input_boxes=ib, multimask_output=False)\n",
    "        logits_low = _norm_logits_shape(out.pred_masks)\n",
    "        logits = F.interpolate(logits_low, size=gt.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        prob = torch.sigmoid(logits)\n",
    "\n",
    "        dice, iou = compute_dice_iou(prob, gt)\n",
    "        dices.append(dice)\n",
    "        ious.append(iou)\n",
    "\n",
    "        if loss_fn is not None:\n",
    "            losses.append(loss_fn(logits, gt).item())\n",
    "\n",
    "        pbar.set_postfix(dice=f\"{dice:.3f}\", iou=f\"{iou:.3f}\")\n",
    "\n",
    "    print(f\"\\n✅ Mean Dice: {torch.tensor(dices).mean():.4f} | Mean IoU: {torch.tensor(ious).mean():.4f}\")\n",
    "    if losses:\n",
    "        print(f\"Avg Val Loss: {torch.tensor(losses).mean():.4f}\")\n",
    "    return torch.tensor(dices).mean().item(), torch.tensor(ious).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, val_dataloader, loss_fn=seg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Mean Dice: 0.3160 | Mean IoU: 0.2199\n",
    "Avg Val Loss: 0.7576"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO3J7NM8GhCD9mRrKlDPVme",
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
